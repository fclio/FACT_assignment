{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c7e442a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7efe508166b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "# DNN libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Import utility functions from other files\n",
    "from utils import generate_model, dp, generate_offline_data\n",
    "from env import Agent, Environment\n",
    "\n",
    "\n",
    "# Plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "plt.style.use('ieee')\n",
    "\n",
    "\n",
    "# Clustering libraries\n",
    "from sklearn.decomposition import PCA\n",
    "from pyclustering.cluster import cluster_visualizer\n",
    "from pyclustering.cluster.xmeans import xmeans\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.utils import read_sample\n",
    "from pyclustering.samples.definitions import SIMPLE_SAMPLES\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Set the seeds\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd6bd24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'd4rl_atari'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3720/3015370865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0male_py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0md4rl_atari\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seaquest-mixed-v0'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# -v{0, 1, 2, 3, 4} for datasets with the other random seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'd4rl_atari'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ale_py\n",
    "import d4rl_atari\n",
    "\n",
    "env = gym.make('seaquest-mixed-v0') # -v{0, 1, 2, 3, 4} for datasets with the other random seeds\n",
    "# env = gym.make('ALE/Breakout-v5')\n",
    "\n",
    "# interaction with its environment through dopamine-style Atari wrapper\n",
    "observation = env.reset() # observation.shape == (84, 84)\n",
    "observation, reward, terminal, info = env.step(env.action_space.sample())\n",
    "\n",
    "# dataset will be automatically downloaded into ~/.d4rl/datasets/[GAME]/[INDEX]/[EPOCH]\n",
    "dataset = env.get_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a2971c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 1, 84, 84)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# print(dataset['observations'])\n",
    "print(dataset['observations'].shape) # observation data in (1000000, 1, 84, 84)\n",
    "print(type(dataset['observations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b266281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "(1000000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset['actions'])) # action data in (1000000,)\n",
    "print(dataset['actions'].shape) # observation data in (1000000, )\n",
    "print(type(dataset['actions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2974aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "(1000000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset['rewards'])) # reward data in (1000000,)\n",
    "print(dataset['rewards'].shape) # observation data in (1000000, )\n",
    "print(type(dataset['rewards']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14cb8b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "(1000000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(dataset['terminals'])) # terminal flags in (1000000,)\n",
    "print(dataset['terminals'].shape) # observation data in (1000000, )\n",
    "print(type(dataset['terminals']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae54de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decision_transformer_atari import GPTConfig, GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dd583b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15867/303368422.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/mnt/c/users/bartd/OneDrive/UvA/Y1/Period3/FACT/xrl_with_trajectories-main/xrl_with_trajectories-main/checkpoints.pth\"\u001b[0m  \u001b[0;31m# or Pong, Qbert, Seaquest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/decision-transformer-atari/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1000\u001b[0m             \"functionality.\")\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m     \u001b[0mmagic_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmagic_number\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mMAGIC_NUMBER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid magic number; corrupt file?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "block_size = 90\n",
    "model_type = \"reward_conditioned\"\n",
    "timesteps = 2654\n",
    "\n",
    "mconf = GPTConfig(\n",
    "    vocab_size,\n",
    "    block_size,\n",
    "    n_layer=6,\n",
    "    n_head=8,\n",
    "    n_embd=128,\n",
    "    model_type=model_type,\n",
    "    max_timestep=timesteps,\n",
    ")\n",
    "model = GPT(mconf)\n",
    "\n",
    "checkpoint_path = \"checkpoints/Breakout_123.pth\"  # or Pong, Qbert, Seaquestcheckpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints? \n",
    "# env?\n",
    "# where are parameter weights? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deca0b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (tok_emb): Embedding(4, 128)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CausalSelfAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "        (resid_drop): Dropout(p=0.1, inplace=False)\n",
       "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU()\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=128, out_features=4, bias=False)\n",
       "  (state_encoder): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (5): ReLU()\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    (7): Linear(in_features=3136, out_features=128, bias=True)\n",
       "    (8): Tanh()\n",
       "  )\n",
       "  (ret_emb): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (action_embeddings): Sequential(\n",
       "    (0): Embedding(4, 128)\n",
       "    (1): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FACT-AI",
   "language": "python",
   "name": "fact-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
